# -*- coding: utf-8 -*-
"""-ELM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1v9BQ6TqvOLZdbr2X5vUdA5ALTad7QjKd

### **Importing Intel tool kits**
"""

!pip install openvino==2024.4.0
!pip install openvino-genai==2024.4.0
!pip install dpctl #Install the dpctl module
!pip install scikit-learn-intelex
#pip install dpctl

import numpy as np
#import dpctl
from sklearnex import patch_sklearn,config_context
patch_sklearn()
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, KFold
from sklearn.metrics import mean_squared_error, r2_score, f1_score
import matplotlib.pyplot as plt
import dpctl #Import the dpctl module

"""### **Data** **pre**-**processing**  """

# Load the data
df = pd.read_csv('Interpolated_Retail_Data.csv')

# Convert 'Date' column to datetime format and extract features
df['Date'] = pd.to_datetime(df['Date'])
df['Year'] = df['Date'].dt.year
df['Month'] = df['Date'].dt.month
df['Day'] = df['Date'].dt.day
df.drop('Date', axis=1, inplace=True)


# Define features (X) and target (y)
X = df[['Year', 'Month', 'Day']].values
y = df[['Rice', 'Wheat', 'Atta (Wheat)', 'Gram Dal', 'Tur/Arhar Dal',
         'Urad Dal', 'Moong Dal', 'Masoor Dal', 'Sugar', 'Milk @',
         'Groundnut Oil (Packed)', 'Mustard Oil (Packed)', 'Vanaspati (Packed)',
         'Soya Oil (Packed)', 'Sunflower Oil (Packed)', 'Palm Oil (Packed)',
         'Gur', 'Tea Loose', 'Salt Pack (Iodised)','Potato','Tomato','Onion']].values
# Scale features
scaler = StandardScaler()
X = scaler.fit_transform(X)

# Scale target variables
y_scaler = StandardScaler()
y = y_scaler.fit_transform(y)

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""### **LSTM Model**"""

import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import numpy as np
import pandas as pd

# Load the data
df = pd.read_csv('Interpolated_Retail_Data.csv')

# Convert 'Date' column to datetime format and extract features
df['Date'] = pd.to_datetime(df['Date'])
df['Year'] = df['Date'].dt.year
df['Month'] = df['Date'].dt.month
df['Day'] = df['Date'].dt.day
df.drop('Date', axis=1, inplace=True)

# Define features (X) and target (y)
X = df[['Year', 'Month', 'Day']].values
y = df[['Rice', 'Wheat', 'Atta (Wheat)', 'Gram Dal', 'Tur/Arhar Dal',
         'Urad Dal', 'Moong Dal', 'Masoor Dal', 'Sugar', 'Milk @',
         'Groundnut Oil (Packed)', 'Mustard Oil (Packed)', 'Vanaspati (Packed)',
         'Soya Oil (Packed)', 'Sunflower Oil (Packed)', 'Palm Oil (Packed)',
         'Gur', 'Tea Loose', 'Salt Pack (Iodised)','Potato','Tomato','Onion']].values

# Scale features
scaler = StandardScaler()
X = scaler.fit_transform(X)

# Scale target variables
y_scaler = StandardScaler()
y = y_scaler.fit_transform(y)

# Reshape X for LSTM input (samples, timesteps, features)
X = np.reshape(X, (X.shape[0], 1, X.shape[1]))

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define the LSTM model
model = Sequential()

# First LSTM layer with Dropout regularization
model.add(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))
model.add(Dropout(0.2))

# Second LSTM layer
model.add(LSTM(units=100, return_sequences=True))
model.add(Dropout(0.2))

# Third LSTM layer
model.add(LSTM(units=50, return_sequences=False))
model.add(Dropout(0.2))

# Output layer (for multi-output regression)
model.add(Dense(units=y_train.shape[1]))

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error')

# Train the model and capture the training history
history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))

# Print the loss and validation loss for each epoch
for i in range(len(history.history['loss'])):
    print(f"Epoch {i+1}, Loss: {history.history['loss'][i]}, Validation Loss: {history.history['val_loss'][i]}")

# Plot the loss and validation loss
plt.figure(figsize=(10, 6))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Loss and Validation Loss over Epochs')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Evaluate the model
mse = model.evaluate(X_test, y_test)
print(f'Mean Squared Error on Test Data: {mse}')

# Make predictions
y_pred = model.predict(X_test)

# Inverse scaling of the predicted results
y_pred_original = y_scaler.inverse_transform(y_pred)
y_test_original = y_scaler.inverse_transform(y_test)

# Display the first 5 predicted and actual results
print(f"Predicted Prices: {y_pred_original[:5]}")
print(f"Actual Prices: {y_test_original[:5]}")

mape = mean_absolute_percentage_error(y_test_original, y_pred_original) * 100  # MAPE in percentage
accuracy = 100 - mape  # Accuracy in percentage

print(f'MAPE: {mape:.2f}%')
print(f'Accuracy: {accuracy:.2f}%')

"""### **Plotting price prediction (lstm model)**"""

commodity_names = ['Rice', 'Wheat', 'Atta (Wheat)', 'Sugar', 'Onion']  # Select some commodities for visualization
commodity_indices = [0, 1, 2, 8, 21]  # Corresponding indices in the dataset

# Plot for each selected commodity
plt.figure(figsize=(14, 8))
for i, commodity_index in enumerate(commodity_indices):
    plt.subplot(3, 2, i+1)
    plt.plot(y_test_original[:, commodity_index], label='Actual Price', color='blue')
    plt.plot(y_pred_original[:, commodity_index], label='Predicted Price', color='red')
    plt.title(f'{commodity_names[i]} Price Prediction')
    plt.xlabel('Sample Index')
    plt.ylabel('Price')
    plt.legend()

plt.tight_layout()
plt.show()

# Function to predict prices based on user input date range
def predict_prices(start_date, end_date):
    # Convert input dates to datetime
    start_date = pd.to_datetime(start_date, format='%d/%m/%Y')
    end_date = pd.to_datetime(end_date, format='%d/%m/%Y')

    # Create a date range
    date_range = pd.date_range(start=start_date, end=end_date)

    # Prepare features for prediction
    features = np.array([[date.year, date.month, date.day] for date in date_range])

    # Scale the features
    features_scaled = scaler.transform(features)

    # Reshape features for LSTM input (samples, timesteps, features)
    features_scaled_reshaped = np.reshape(features_scaled, (features_scaled.shape[0], 1, features_scaled.shape[1]))

    # Make predictions using the trained LSTM model
    predicted_prices_scaled = model.predict(features_scaled_reshaped)

    # Inverse transform the predictions to get original scale
    predicted_prices = y_scaler.inverse_transform(predicted_prices_scaled)

    # Create a DataFrame for the results
    results_df = pd.DataFrame(predicted_prices, columns=['Rice', 'Wheat', 'Atta (Wheat)', 'Gram Dal',
                                                         'Tur/Arhar Dal', 'Urad Dal', 'Moong Dal',
                                                         'Masoor Dal', 'Sugar', 'Milk @',
                                                         'Groundnut Oil (Packed)', 'Mustard Oil (Packed)',
                                                         'Vanaspati (Packed)', 'Soya Oil (Packed)',
                                                         'Sunflower Oil (Packed)', 'Palm Oil (Packed)',
                                                         'Gur', 'Tea Loose', 'Salt Pack (Iodised)', 'Potato', 'Tomato', 'Onion'])

    results_df['Date'] = date_range

    # Reorder columns to have Date first
    return results_df[['Date'] + list(results_df.columns[:-1])]

# Example usage: Get user input for date range
start_date = input("Enter the start date (DD/MM/YYYY): ")
end_date = input("Enter the end date (DD/MM/YYYY): ")

predicted_prices_df = predict_prices(start_date, end_date)
print("\nPredicted prices from", start_date, "to", end_date)
print(predicted_prices_df)

"""### **LSTM model with Hyper parameter fine tuning**"""

import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import numpy as np
import pandas as pd

# Load the data
df = pd.read_csv('Interpolated_Retail_Data.csv')

# Convert 'Date' column to datetime format and extract features
df['Date'] = pd.to_datetime(df['Date'])
df['Year'] = df['Date'].dt.year
df['Month'] = df['Date'].dt.month
df['Day'] = df['Date'].dt.day
df.drop('Date', axis=1, inplace=True)

# Define features (X) and target (y)
X = df[['Year', 'Month', 'Day']].values
y = df[['Rice', 'Wheat', 'Atta (Wheat)', 'Gram Dal', 'Tur/Arhar Dal',
         'Urad Dal', 'Moong Dal', 'Masoor Dal', 'Sugar', 'Milk @',
         'Groundnut Oil (Packed)', 'Mustard Oil (Packed)', 'Vanaspati (Packed)',
         'Soya Oil (Packed)', 'Sunflower Oil (Packed)', 'Palm Oil (Packed)',
         'Gur', 'Tea Loose', 'Salt Pack (Iodised)','Potato','Tomato','Onion']].values

# Scale features
scaler = StandardScaler()
X = scaler.fit_transform(X)

# Scale target variables
y_scaler = StandardScaler()
y = y_scaler.fit_transform(y)

# Reshape X for LSTM input (samples, timesteps, features)
X = np.reshape(X, (X.shape[0], 1, X.shape[1]))

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define the LSTM model with hyperparameters
model = Sequential()

# First LSTM layer with Dropout regularization
model.add(LSTM(units=150, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))
model.add(Dropout(0.3))  # Increased dropout to avoid overfitting

# Second LSTM layer
model.add(LSTM(units=100, return_sequences=True))
model.add(Dropout(0.3))

# Third LSTM layer
model.add(LSTM(units=50, return_sequences=False))
model.add(Dropout(0.3))

# Output layer (for multi-output regression)
model.add(Dense(units=y_train.shape[1]))

# Compile the model with Adam optimizer and tuned learning rate
optimizer = Adam(learning_rate=0.001)  # Reduced learning rate
model.compile(optimizer=optimizer, loss='mean_squared_error')

# Train the model and capture the training history
history = model.fit(X_train, y_train, epochs=100, batch_size=64, validation_data=(X_test, y_test))

# Print the loss and validation loss for each epoch
for i in range(len(history.history['loss'])):
    print(f"Epoch {i+1}, Loss: {history.history['loss'][i]}, Validation Loss: {history.history['val_loss'][i]}")

# Plot the loss and validation loss
plt.figure(figsize=(10, 6))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Loss and Validation Loss over Epochs')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Evaluate the model
mse = model.evaluate(X_test, y_test)
print(f'Mean Squared Error on Test Data: {mse}')

# Make predictions
y_pred = model.predict(X_test)

# Inverse scaling of the predicted results
y_pred_original = y_scaler.inverse_transform(y_pred)
y_test_original = y_scaler.inverse_transform(y_test)

# Display the first 5 predicted and actual results
print(f"Predicted Prices: {y_pred_original[:5]}")
print(f"Actual Prices: {y_test_original[:5]}")

# Calculate mean absolute percentage error (MAPE) for accuracy
mape = np.mean(np.abs((y_test_original - y_pred_original) / y_test_original)) * 100
accuracy = 100 - mape  # Percentage accuracy
print(f'MAPE: {mape}%')
print(f'Accuracy: {accuracy}%')

# Plot percentage accuracy
epochs = range(1, len(history.history['loss']) + 1)

plt.figure(figsize=(10, 6))
plt.plot(epochs, [accuracy] * len(epochs), label='Accuracy (%)')
plt.title('Accuracy over Epochs')
plt.xlabel('Epochs')
plt.ylabel('Accuracy (%)')
plt.legend()
plt.show()

"""### **LSTM model with stratified kfold cross evaluation**"""

import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import KFold
import numpy as np
import pandas as pd

# Load the data
df = pd.read_csv('Interpolated_Retail_Data.csv')

# Convert 'Date' column to datetime format and extract features
df['Date'] = pd.to_datetime(df['Date'])
df['Year'] = df['Date'].dt.year
df['Month'] = df['Date'].dt.month
df['Day'] = df['Date'].dt.day

# Define features (X) and target (y)
X = df[['Year', 'Month', 'Day']].values
y = df[['Rice', 'Wheat', 'Atta (Wheat)', 'Gram Dal', 'Tur/Arhar Dal',
         'Urad Dal', 'Moong Dal', 'Masoor Dal', 'Sugar', 'Milk @',
         'Groundnut Oil (Packed)', 'Mustard Oil (Packed)', 'Vanaspati (Packed)',
         'Soya Oil (Packed)', 'Sunflower Oil (Packed)', 'Palm Oil (Packed)',
         'Gur', 'Tea Loose', 'Salt Pack (Iodised)', 'Potato', 'Tomato', 'Onion']].values

# Scale features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Scale target variables
y_scaler = StandardScaler()
y_scaled = y_scaler.fit_transform(y)

# Reshape X for LSTM input (samples, timesteps, features)
X_scaled = np.reshape(X_scaled, (X_scaled.shape[0], 1, X_scaled.shape[1]))

# Set up K-Fold Cross Validation
kfold = KFold(n_splits=5, shuffle=False)  # shuffle=False to maintain temporal order
fold_no = 1
mse_per_fold = []
mape_per_fold = []

for train_index, test_index in kfold.split(X_scaled):
    print(f'Starting fold {fold_no}...')

    X_train, X_test = X_scaled[train_index], X_scaled[test_index]
    y_train, y_test = y_scaled[train_index], y_scaled[test_index]

    # Define the LSTM model with hyperparameters
    model = Sequential()

    # First LSTM layer with Dropout regularization
    model.add(LSTM(units=150, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))
    model.add(Dropout(0.3))

    # Second LSTM layer
    model.add(LSTM(units=100, return_sequences=True))
    model.add(Dropout(0.3))

    # Third LSTM layer
    model.add(LSTM(units=50, return_sequences=False))
    model.add(Dropout(0.3))

    # Output layer (for multi-output regression)
    model.add(Dense(units=y_train.shape[1]))

    # Compile the model
    optimizer = Adam(learning_rate=0.001)
    model.compile(optimizer=optimizer, loss='mean_squared_error')

    # Train the model
    history = model.fit(X_train, y_train, epochs=50, batch_size=64, validation_data=(X_test, y_test), verbose=0)

    # Evaluate the model
    mse = model.evaluate(X_test, y_test, verbose=0)
    mse_per_fold.append(mse)

    # Make predictions
    y_pred = model.predict(X_test)

    # Inverse scaling of the predicted results
    y_pred_original = y_scaler.inverse_transform(y_pred)
    y_test_original = y_scaler.inverse_transform(y_test)

    # Calculate MAPE
    mape = np.mean(np.abs((y_test_original - y_pred_original) / y_test_original)) * 100
    mape_per_fold.append(mape)

    print(f'Fold {fold_no} - MSE: {mse}, MAPE: {mape}%')

    # Plot training & validation loss values
    plt.figure(figsize=(10, 4))
    plt.plot(history.history['loss'], label='Training Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.title(f'Fold {fold_no} - Loss over Epochs')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.show()

    fold_no += 1

# Print overall results
print('------------------------------------------------------------------------')
print('Score per fold')
for i in range(0, len(mse_per_fold)):
    print(f'> Fold {i+1} - MSE: {mse_per_fold[i]}, MAPE: {mape_per_fold[i]}%')
print('------------------------------------------------------------------------')
print(f'Average MSE: {np.mean(mse_per_fold)}')
print(f'Average MAPE: {np.mean(mape_per_fold)}%')

import numpy as np
from sklearn.metrics import mean_absolute_percentage_error

# Assuming y_pred and y_test contain the predicted and actual values after inverse scaling

# Inverse scaling of the predicted results (already provided in your previous code)
y_pred_original = y_scaler.inverse_transform(y_pred)
y_test_original = y_scaler.inverse_transform(y_test)

# Calculate MAPE for accuracy
mape = mean_absolute_percentage_error(y_test_original, y_pred_original) * 100  # MAPE in percentage
accuracy = 100 - mape  # Accuracy in percentage

print(f'MAPE: {mape:.2f}%')
print(f'Accuracy: {accuracy:.2f}%')
