# -*- coding: utf-8 -*-
"""SwarmFireflyOptimizationlAlgorithm.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Sw3gl-SqzfUV3dPKS09fDnLVnN9O6WW_

**LOADING DATASET AND CHECKING**
"""

import pandas as pd

data = pd.read_csv('retaildata.csv')

# Check the structure and the first few rows of the dataset
data.info(), data.head()

"""**SFOA-ELM MODEL DEFINITION:**"""

class ELM:
    def __init__(self, input_dim, hidden_dim, regularization=0.0):
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        self.regularization = regularization
        self.W = None
        self.b = None
        self.beta = None

    def fit(self, X, y):
        self.W = np.random.randn(self.hidden_dim, self.input_dim)
        self.b = np.random.randn(self.hidden_dim, 1)

        H = self._hidden_layer_output(X)
        I = np.eye(H.shape[1])
        self.beta = np.linalg.pinv(H.T @ H + self.regularization * I) @ H.T @ y

    def _hidden_layer_output(self, X):
        return 1 / (1 + np.exp(- (X @ self.W.T + self.b.T)))

    def predict(self, X):
        H = self._hidden_layer_output(X)
        return H @ self.beta

"""**VARIATION OF PRICES ACROSS THE TIME PERIOD**"""

import pandas as pd
import matplotlib.pyplot as plt

# Load the data
df = pd.read_csv('retaildata.csv')

# Convert 'Date' column to datetime format
df['Date'] = pd.to_datetime(df['Date'], format="%d/%m/%Y")

# Define target variables
target_names = ['Rice', 'Wheat', 'Atta (Wheat)', 'Gram Dal', 'Tur/Arhar Dal',
                'Urad Dal', 'Moong Dal', 'Masoor Dal', 'Sugar', 'Milk @',
                'Groundnut Oil (Packed)', 'Mustard Oil (Packed)', 'Vanaspati (Packed)',
                'Soya Oil (Packed)', 'Sunflower Oil (Packed)', 'Palm Oil (Packed)',
                'Gur', 'Tea Loose', 'Salt Pack (Iodised)', 'Potato', 'Onion', 'Tomato']

# Create a figure and axis for plotting
plt.figure(figsize=(15, 10))

# Loop through each target variable and plot
for i, target in enumerate(target_names):
    plt.subplot(5, 5, i + 1)  # Create a grid of subplots (5x5)
    plt.plot(df['Date'], df[target], label=target, color='blue')
    plt.title(target)
    plt.xlabel('Date')
    plt.ylabel('Price')
    plt.xticks(rotation=45)
    plt.grid()

# Adjust layout
plt.tight_layout()
plt.suptitle('Target Values Over Time', fontsize=16, y=1.02)
plt.show()

"""**F1 SCORE**"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score, f1_score
import matplotlib.pyplot as plt

# Load the data
df = pd.read_csv('retaildata.csv')

# Convert 'Date' column to datetime format and extract features
df['Date'] = pd.to_datetime(df['Date'], format="%d/%m/%Y")
df['Year'] = df['Date'].dt.year
df['Month'] = df['Date'].dt.month
df['Day'] = df['Date'].dt.day
df.drop('Date', axis=1, inplace=True)

# Define features (X) and target (y)
X = df[['Year', 'Month', 'Day']].values
y = df[['Rice', 'Wheat', 'Atta (Wheat)', 'Gram Dal', 'Tur/Arhar Dal',
         'Urad Dal', 'Moong Dal', 'Masoor Dal', 'Sugar', 'Milk @',
         'Groundnut Oil (Packed)', 'Mustard Oil (Packed)', 'Vanaspati (Packed)',
         'Soya Oil (Packed)', 'Sunflower Oil (Packed)', 'Palm Oil (Packed)',
         'Gur', 'Tea Loose', 'Salt Pack (Iodised)', 'Potato', 'Onion', 'Tomato']].values

# Scale features
scaler = StandardScaler()
X = scaler.fit_transform(X)

# Scale target variables
y_scaler = StandardScaler()
y = y_scaler.fit_transform(y)

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define the ELM model
class ELM:
    def __init__(self, input_dim, hidden_dim, regularization=0.0):
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        self.regularization = regularization
        self.W = None
        self.b = None
        self.beta = None

    def fit(self, X, y):
        self.W = np.random.randn(self.hidden_dim, self.input_dim)
        self.b = np.random.randn(self.hidden_dim, 1)

        H = self._hidden_layer_output(X)
        I = np.eye(H.shape[1])
        self.beta = np.linalg.pinv(H.T @ H + self.regularization * I) @ H.T @ y

    def _hidden_layer_output(self, X):
        return 1 / (1 + np.exp(- (X @ self.W.T + self.b.T)))

    def predict(self, X):
        H = self._hidden_layer_output(X)
        return H @ self.beta

# Define the Firefly Algorithm for optimization
class FireflyAlgorithm:
    def __init__(self, n_fireflies, n_iterations, input_dim, hidden_dim, X, y, reg_param=0.01):
        self.n_fireflies = n_fireflies
        self.n_iterations = n_iterations
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        self.X = X
        self.y = y
        self.reg_param = reg_param
        self.best_firefly = None
        self.best_score = float('inf')
        self.best_model = None

    def optimize(self):
        fireflies = np.random.uniform(-1, 1, (self.n_fireflies, self.input_dim * self.hidden_dim + self.hidden_dim))
        scores = np.zeros(self.n_fireflies)

        for iteration in range(self.n_iterations):
            for i in range(self.n_fireflies):
                W, b = self.decode_firefly(fireflies[i])
                elm = ELM(self.input_dim, self.hidden_dim, self.reg_param)
                elm.W = W
                elm.b = b
                elm.fit(self.X, self.y)
                predictions = elm.predict(self.X)

                score = np.mean((predictions - self.y) ** 2)
                scores[i] = score

                if score < self.best_score:
                    self.best_score = score
                    self.best_firefly = fireflies[i]
                    self.best_model = elm

            fireflies = self.move_fireflies(fireflies, scores)

        return self.best_model

    def decode_firefly(self, firefly):
        W = firefly[:self.hidden_dim * self.input_dim].reshape((self.hidden_dim, self.input_dim))
        b = firefly[self.hidden_dim * self.input_dim:].reshape((self.hidden_dim, 1))
        return W, b

    def move_fireflies(self, fireflies, scores):
        attractiveness = np.exp(-np.array(scores))
        for i in range(self.n_fireflies):
            for j in range(self.n_fireflies):
                if scores[i] < scores[j]:
                    distance = np.linalg.norm(fireflies[i] - fireflies[j])
                    attractiveness_i = attractiveness[j] / (1 + distance)
                    fireflies[i] += attractiveness_i * np.random.rand() * (fireflies[j] - fireflies[i])
        return fireflies

# Train the model using the Firefly Algorithm
input_dim = X_train.shape[1]
hidden_dim = 70
n_fireflies = 40
n_iterations = 200

fa = FireflyAlgorithm(n_fireflies, n_iterations, input_dim, hidden_dim, X_train, y_train)
best_model = fa.optimize()

# Make predictions on the test set
predictions = best_model.predict(X_test)

# Inverse scale the predictions for RMSE and R²
predictions = y_scaler.inverse_transform(predictions)
y_test = y_scaler.inverse_transform(y_test)

# Calculate RMSE and R² score
rmse = np.sqrt(mean_squared_error(y_test, predictions))
r2 = r2_score(y_test, predictions)

# Print RMSE and R² score
print(f"RMSE: {rmse:.2f}")
print(f"R² Score: {r2:.2f}")

# Calculate F1 Score (for each target variable)
# Adjust the threshold based on your needs
threshold = 0.5  # This should be adjusted based on the expected value range
predictions_binary = (predictions > threshold).astype(int)
y_test_binary = (y_test > threshold).astype(int)

f1_scores = []
for i in range(predictions_binary.shape[1]):
    f1 = f1_score(y_test_binary[:, i], predictions_binary[:, i], average='weighted')
    f1_scores.append(f1)
    print(f"F1 Score for target variable {i + 1}: {f1:.2f}")

# Calculate average F1 Score
average_f1_score = np.mean(f1_scores)
print(f"Average F1 Score across all target variables: {average_f1_score:.2f}")

# Visualize the target values over time
plt.figure(figsize=(15, 6))
plt.plot(df['Year'] + (df['Month'] - 1) / 12 + (df['Day'] - 1) / 365, df['Rice'], label='Rice', color='blue')
plt.plot(df['Year'] + (df['Month'] - 1) / 12 + (df['Day'] - 1) / 365, df['Wheat'], label='Wheat', color='orange')
plt.xlabel('Time')
plt.ylabel('Price')
plt.title('Commodity Prices Over Time')
plt.legend()
plt.grid()
plt.show()

import pandas as pd
from statsmodels.tsa.arima.model import ARIMA
import matplotlib.pyplot as plt

# Load data
df = pd.read_csv('retaildata.csv')
df['Date'] = pd.to_datetime(df['Date'], format="%d/%m/%Y")
df.set_index('Date', inplace=True)

# Fit ARIMA model for Rice prices
rice_prices = df['Tomato']
model = ARIMA(rice_prices, order=(6, 20, 45))  # Example order, adjust as needed
model_fit = model.fit()

# Make predictions
predictions = model_fit.forecast(steps=10)  # Predict the next 10 periods
print(predictions)

# Plot results
plt.figure(figsize=(12, 6))
plt.plot(rice_prices.index, rice_prices, label='Historical Rice Prices')
plt.plot(pd.date_range(start=rice_prices.index[-1], periods=11, freq='M')[1:], predictions, label='Forecast', color='red')
plt.title('tomato Price Forecast')
plt.xlabel('Date')
plt.ylabel('Price')
plt.legend()
plt.show()

import pandas as pd
from statsmodels.tsa.arima.model import ARIMA
import matplotlib.pyplot as plt

# Load data
df = pd.read_csv('retaildata.csv')
df['Date'] = pd.to_datetime(df['Date'], format="%d/%m/%Y")
df.set_index('Date', inplace=True)

# Fit ARIMA model for Rice prices
rice_prices = df['Rice']
model = ARIMA(rice_prices, order=(1, 1, 1))  # Example order, adjust as needed
model_fit = model.fit()

# Make predictions
predictions = model_fit.forecast(steps=10)  # Predict the next 10 periods
print(predictions)

# Plot results
plt.figure(figsize=(12, 6))
plt.plot(rice_prices.index, rice_prices, label='Historical Rice Prices')
plt.plot(pd.date_range(start=rice_prices.index[-1], periods=11, freq='M')[1:], predictions, label='Forecast', color='red')
plt.title('Rice Price Forecast')
plt.xlabel('Date')
plt.ylabel('Price')
plt.legend()
plt.show()

from statsmodels.tsa.statespace.sarimax import SARIMAX

# Fit SARIMA model
model_sarima = SARIMAX(rice_prices, order=(1, 1, 1), seasonal_order=(1, 1, 1, 12))
model_sarima_fit = model_sarima.fit()

# Make predictions
predictions_sarima = model_sarima_fit.forecast(steps=10)

# Plot results
plt.figure(figsize=(12, 6))
plt.plot(rice_prices.index, rice_prices, label='Historical Rice Prices')
plt.plot(pd.date_range(start=rice_prices.index[-1], periods=11, freq='M')[1:], predictions_sarima, label='SARIMA Forecast', color='green')
plt.title('SARIMA Model - Rice Price Forecast')
plt.xlabel('Date')
plt.ylabel('Price')
plt.legend()
plt.show()









"""**PRICE PREDICTION AT RANDOM DATE:**"""

def predict_prices(input_date):
    # Convert input date to datetime
    date = pd.to_datetime(input_date, format="%d/%m/%Y")

    # Extract features
    features = np.array([[date.year, date.month, date.day]])

    # Scale the features using the same scaler
    features_scaled = scaler.transform(features)

    # Make predictions using the trained model
    predictions_scaled = best_model.predict(features_scaled)

    # Inverse transform the predictions to get original scale
    predictions = y_scaler.inverse_transform(predictions_scaled)

    # Create a dictionary for better readability
    target_names = ['Rice', 'Wheat', 'Atta (Wheat)', 'Gram Dal', 'Tur/Arhar Dal',
                    'Urad Dal', 'Moong Dal', 'Masoor Dal', 'Sugar', 'Milk @',
                    'Groundnut Oil (Packed)', 'Mustard Oil (Packed)', 'Vanaspati (Packed)',
                    'Soya Oil (Packed)', 'Sunflower Oil (Packed)', 'Palm Oil (Packed)',
                    'Gur', 'Tea Loose', 'Salt Pack (Iodised)', 'Potato', 'Onion', 'Tomato']

    price_predictions = {target_names[i]: predictions[0][i] for i in range(len(target_names))}
    return price_predictions

# Example usage: Predict prices for a given date
user_date = input("Enter a date (DD/MM/YYYY): ")
predicted_prices = predict_prices(user_date)
print(f"Predicted prices for {user_date}:")
for item, price in predicted_prices.items():
    print(f"{item}: {price:.2f}")

# Evaluate the model
predictions = best_model.predict(X_test)

# Calculate RMSE and R² score
rmse = np.sqrt(mean_squared_error(y_test, predictions))
r2 = r2_score(y_test, predictions)

# Print RMSE and R² score
print(f"RMSE: {rmse:.2f}")
print(f"R² Score: {r2:.2f}")
threshold = 0.5  # Adjust based on your needs
predictions_binary = (predictions > threshold).astype(int)
y_test_binary = (y_scaler.inverse_transform(y_test) > threshold).astype(int)


# Calculate average F1 Score

# Visualize the target values over time
plt.figure(figsize=(15, 6))
plt.plot(df['Year'] + (df['Month'] - 1) / 12 + (df['Day'] - 1) / 365, df['Rice'], label='Rice', color='blue')
plt.plot(df['Year'] + (df['Month'] - 1) / 12 + (df['Day'] - 1) / 365, df['Wheat'], label='Wheat', color='orange')
plt.xlabel('Time')
plt.ylabel('Price')
plt.title('Commodity Prices Over Time')
plt.legend()
plt.grid()
plt.show()

"""**RMSE AND R2 VALUES:**"""

# Evaluate the model
predictions = best_model.predict(X_test)

# Calculate RMSE and R² score
rmse = np.sqrt(mean_squared_error(y_test, predictions))
r2 = r2_score(y_test, predictions)

# Print RMSE and R² score
print(f"RMSE: {rmse:.2f}")
print(f"R² Score: {r2:.2f}")

# Plotting the accuracy of each target variable
r2_scores = []

for i in range(predictions.shape[1]):
    r2 = r2_score(y_test[:, i], predictions[:, i])
    r2_scores.append(r2)

# Plotting the R² scores
plt.figure(figsize=(15, 6))
plt.bar(range(len(r2_scores)), r2_scores, color='skyblue')
plt.xticks(range(len(r2_scores)), [f'Target {i + 1}' for i in range(len(r2_scores))], rotation=45)
plt.xlabel('Target Variables')
plt.ylabel('R² Score')
plt.title('R² Score of Predictions for Each Target Variable')
plt.ylim(-1, 1)  # Set y-axis limits from -1 to 1 for better visualization
plt.grid(axis='y')
plt.tight_layout()
plt.show()

# Function to predict prices based on user input date
def predict_prices(input_date):
    # Convert input date to datetime
    date = pd.to_datetime(input_date, format="%d/%m/%Y")

    # Extract features
    features = np.array([[date.year, date.month, date.day]])

    # Scale the features using the same scaler
    features_scaled = scaler.transform(features)

    # Make predictions using the trained model
    predictions_scaled = best_model.predict(features_scaled)

    # Inverse transform the predictions to get original scale
    predictions = y_scaler.inverse_transform(predictions_scaled)

    # Create a dictionary for better readability
    target_names = ['Rice', 'Wheat', 'Atta (Wheat)', 'Gram Dal', 'Tur/Arhar Dal',
                    'Urad Dal', 'Moong Dal', 'Masoor Dal', 'Sugar', 'Milk @',
                    'Groundnut Oil (Packed)', 'Mustard Oil (Packed)', 'Vanaspati (Packed)',
                    'Soya Oil (Packed)', 'Sunflower Oil (Packed)', 'Palm Oil (Packed)',
                    'Gur', 'Tea Loose', 'Salt Pack (Iodised)', 'Potato', 'Onion', 'Tomato']

    price_predictions = {target_names[i]: predictions[0][i] for i in range(len(target_names))}

    return price_predictions

# Example usage: Predict prices for a given date
user_date = input("Enter a date (DD/MM/YYYY): ")
predicted_prices = predict_prices(user_date)
print(f"Predicted prices for {user_date}:")
for item, price in predicted_prices.items():
    print(f"{item}: {price:.2f}")

"""**K-FOLD CROSS VALIDATION:**"""

from sklearn.model_selection import train_test_split, KFold
kf = KFold(n_splits=10, shuffle=True, random_state=42)
rmse_scores = []
r2_scores = []

for train_index, val_index in kf.split(X):
    X_train, X_val = X[train_index], X[val_index]
    y_train, y_val = y[train_index], y[val_index]

    fa = FireflyAlgorithm(n_fireflies=40, n_iterations=200, input_dim=X_train.shape[1], hidden_dim=70, X=X_train, y=y_train)
    best_model = fa.optimize()

    predictions = best_model.predict(X_val)

    rmse = np.sqrt(mean_squared_error(y_val, predictions))
    r2 = r2_score(y_val, predictions)

    rmse_scores.append(rmse)
    r2_scores.append(r2)

# Plot the results
plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.plot(range(1, len(rmse_scores) + 1), rmse_scores)
plt.xlabel('Fold')
plt.ylabel('RMSE')
plt.title('RMSE for Each Fold')

plt.subplot(1, 2, 2)
plt.plot(range(1, len(r2_scores) + 1), r2_scores)
plt.xlabel('Fold')
plt.ylabel('R² Score')
plt.title('R² Score for Each Fold')

plt.tight_layout()
plt.show()

"""**FROM TO TO DATE PREDICTION**"""

predictions = best_model.predict(X_test)

# Function to predict prices based on user input date range
def predict_prices(start_date, end_date):
    # Convert input dates to datetime
    start_date = pd.to_datetime(start_date)
    end_date = pd.to_datetime(end_date)

    # Create a date range
    date_range = pd.date_range(start=start_date, end=end_date)

    # Prepare features for prediction
    features = np.array([[date.year, date.month, date.day] for date in date_range])
    features_scaled = scaler.transform(features)

    # Make predictions using the trained model
    predicted_prices_scaled = best_model.predict(features_scaled)

    # Inverse transform the predictions to get original scale
    predicted_prices = y_scaler.inverse_transform(predicted_prices_scaled)

    # Create a DataFrame for the results
    results_df = pd.DataFrame(predicted_prices, columns=['Rice', 'Wheat', 'Atta (Wheat)', 'Gram Dal',
                                                          'Tur/Arhar Dal', 'Urad Dal', 'Moong Dal',
                                                          'Masoor Dal', 'Sugar', 'Milk @',
                                                          'Groundnut Oil (Packed)', 'Mustard Oil (Packed)',
                                                          'Vanaspati (Packed)', 'Soya Oil (Packed)',
                                                          'Sunflower Oil (Packed)', 'Palm Oil (Packed)',
                                                          'Gur', 'Tea Loose', 'Salt Pack (Iodised)',
                                                          'Potato', 'Onion', 'Tomato'])
    results_df['Date'] = date_range

    return results_df[['Date'] + list(results_df.columns[:-1])]

# Example usage: Get user input for date range
start_date = input("Enter the start date (DD/MM/YYYY): ")
end_date = input("Enter the end date (DD/MM/YYYY): ")

predicted_prices_df = predict_prices(start_date, end_date)
print("\nPredicted prices from", start_date, "to", end_date)
print(predicted_prices_df)

"""**CALCULATION OF MAE OVER THE ALL THE FOLDS:**"""

# Initialize lists to hold scores
mae_scores = []
r2_scores = []

# Perform stratified K-Fold cross-validation
for fold, (train_index, test_index) in enumerate(skf.split(X, np.zeros(X.shape[0]))):  # Using zeros for stratification
    print(f"Starting fold {fold + 1}...")
    start_time = time.time()  # Start timing

    X_train, X_test = X[train_index], X[test_index]
    y_train, y_test = y[train_index], y[test_index]

    # Initialize and train the ELM model
    input_dim = X_train.shape[1]
    hidden_dim = 70
    elm_model = ELM(input_dim=input_dim, hidden_dim=hidden_dim)
    elm_model.fit(X_train, y_train)

    # Make predictions using the model
    predictions = elm_model.predict(X_test)

    # Calculate MAE and R² score
    mae = mean_absolute_error(y_test, predictions)
    r2 = r2_score(y_test, predictions)

    mae_scores.append(mae)
    r2_scores.append(r2)

    end_time = time.time()  # End timing
    print(f"Fold {fold + 1} completed. MAE: {mae:.2f}, R²: {r2:.2f}, Time taken: {end_time - start_time:.2f} seconds")
    print("---")

# Print average MAE and R² score
print(f"Average MAE: {np.mean(mae_scores):.2f}")
print(f"Average R² Score: {np.mean(r2_scores):.2f}")

# Plot MAE scores
plt.figure(figsize=(12, 6))
plt.plot(range(1, len(mae_scores) + 1), mae_scores, marker='o')
plt.xlabel('Fold')
plt.ylabel('Mean Absolute Error (MAE)')
plt.title('MAE for Each Fold')
plt.grid()
plt.show()

# Heatmap for MAE scores
mae_matrix = np.array(mae_scores).reshape(1, -1)  # Reshape for heatmap
plt.figure(figsize=(10, 1))
sns.heatmap(mae_matrix, annot=True, fmt=".2f", cmap="YlGnBu", cbar=False, xticklabels=[f'Fold {i+1}' for i in range(len(mae_scores))])
plt.title("MAE Heatmap")
plt.xlabel("Folds")
plt.ylabel("MAE")
plt.show()

"""**CALCULATION OF LOG LOSS, MAE, ROC CURVE AND PRECISION RECALL CURVE:**"""

# Initialize lists to hold scores
mae_scores = []
log_loss_scores = []
confusion_matrices = []

# Perform stratified K-Fold cross-validation for each target variable
for target_index in range(y_binary.shape[1]):
    print(f"Evaluating target variable: {df.columns[target_index]}")
    mae_scores_target = []
    log_loss_scores_target = []
    confusion_matrices_target = []

    for fold, (train_index, test_index) in enumerate(skf.split(X, y_binary[:, target_index])):  # Stratify by the current target
        print(f"Starting fold {fold + 1}...")
        start_time = time.time()  # Start timing

        X_train, X_test = X[train_index], X[test_index]
        y_train, y_test = y_binary[train_index, target_index], y_binary[test_index, target_index]

        # Initialize and train the ELM model
        input_dim = X_train.shape[1]
        hidden_dim = 70
        elm_model = ELM(input_dim=input_dim, hidden_dim=hidden_dim)
        elm_model.fit(X_train, y_train)

        # Make predictions using the model
        predictions = elm_model.predict(X_test)

        # Convert predictions to probabilities using sigmoid
        predictions_proba = 1 / (1 + np.exp(-predictions))

        # Calculate MAE
        mae = mean_absolute_error(y_test, predictions_proba > 0.5)  # Convert to binary
        mae_scores_target.append(mae)

        # Calculate Log Loss if both classes are present
        if len(np.unique(y_test)) == 2:  # Check if both classes are present
            log_loss_value = log_loss(y_test, predictions_proba)
            log_loss_scores_target.append(log_loss_value)
        else:
            print(f"Skipping Log Loss calculation for {df.columns[target_index]} due to only one unique label in y_true.")
            print(f"y_true values: {y_test}")  # Print the y_true values
            log_loss_scores_target.append(np.nan)  # Append NaN for log loss if not applicable

        # Calculate Confusion Matrix
        y_pred_binary = (predictions_proba > 0.5).astype(int)
        cm = confusion_matrix(y_test, y_pred_binary)
        confusion_matrices_target.append(cm)

        end_time = time.time()  # End timing
        print(f"Fold {fold + 1} completed. MAE: {mae:.2f}, Time taken: {end_time - start_time:.2f} seconds")
        print("---")

    # Print average MAE and Log Loss for the current target variable
    print(f"Average MAE for {df.columns[target_index]}: {np.mean(mae_scores_target):.2f}")
    if len(log_loss_scores_target) > 0 and not np.all(np.isnan(log_loss_scores_target)):
        print(f"Average Log Loss for {df.columns[target_index]}: {np.nanmean(log_loss_scores_target):.2f}")

    # Plot MAE scores for the current target variable
    plt.figure(figsize=(12, 6))
    plt.plot(range(1, len(mae_scores_target) + 1), mae_scores_target, marker='o')
    plt.xlabel('Fold')
    plt.ylabel('Mean Absolute Error (MAE)')
    plt.title(f'MAE for Each Fold - {df.columns[target_index]}')
    plt.grid()
    plt.show()

    # Heatmap for Log Loss scores
    log_loss_matrix = np.array(log_loss_scores_target).reshape(1, -1)  # Reshape for heatmap
    plt.figure(figsize=(10, 1))
    sns.heatmap(log_loss_matrix, annot=True, fmt=".2f", cmap="YlGnBu", cbar=False, xticklabels=[f'Fold {i+1}' for i in range(len(log_loss_scores_target))])
    plt.title(f"Log Loss Heatmap - {df.columns[target_index]}")
    plt.xlabel("Folds")
    plt.ylabel("Log Loss")
    plt.show()

    # Plot ROC Curve
    plt.figure(figsize=(12, 6))
    fpr, tpr, _ = roc_curve(y_test, predictions_proba)
    plt.plot(fpr, tpr, label=f'ROC Curve for {df.columns[target_index]}')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('ROC Curve')
    plt.legend()
    plt.grid()
    plt.show()

    # Plot Precision-Recall Curve
    plt.figure(figsize=(12, 6))
    precision, recall, _ = precision_recall_curve(y_test, predictions_proba)
    plt.plot(recall, precision, label=f'Precision-Recall Curve for {df.columns[target_index]}')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend()
    plt.grid()
    plt.show()

"""**ACCURACY CALCULATION :**"""

# Create a figure and axis object
fig, ax = plt.subplots(figsize=(12, 6))

# Perform stratified K-Fold cross-validation for each target variable
for target_index in range(y_binary.shape[1]):
    accuracy_scores = []

    for fold, (train_index, test_index) in enumerate(skf.split(X, y_binary[:, target_index])):  # Stratify by the current target
        X_train, X_test = X[train_index], X[test_index]
        y_train, y_test = y_binary[train_index, target_index], y_binary[test_index, target_index]

        # Initialize and train the ELM model
        input_dim = X_train.shape[1]
        hidden_dim = 70
        elm_model = ELM(input_dim=input_dim, hidden_dim=hidden_dim)
        elm_model.fit(X_train, y_train)

        # Make predictions using the model
        predictions = elm_model.predict(X_test)

        # Convert predictions to binary classes based on threshold
        predictions_binary = (predictions > 0.5).astype(int)

        # Calculate accuracy
        accuracy = accuracy_score(y_test, predictions_binary)
        accuracy_scores.append(accuracy)

    # Plot the accuracy scores for the current target variable
    ax.plot(range(1, len(accuracy_scores) + 1), accuracy_scores, label=df.columns[target_index])

# Add labels and title
ax.set_xlabel('Fold')
ax.set_ylabel('Accuracy')
ax.set_title('Accuracy for Each Target Variable')
ax.legend()

# Show the plot
plt.show()

# Perform stratified K-Fold cross-validation for each target variable
for target_index in range(y_binary.shape[1]):
    print(f"Evaluating target variable: {df.columns[target_index]}")
    accuracy_scores = []

    for fold, (train_index, test_index) in enumerate(skf.split(X, y_binary[:, target_index])):  # Stratify by the current target
        print(f"Starting fold {fold + 1}...")

        X_train, X_test = X[train_index], X[test_index]
        y_train, y_test = y_binary[train_index, target_index], y_binary[test_index, target_index]

        # Initialize and train the ELM model
        input_dim = X_train.shape[1]
        hidden_dim = 70
        elm_model = ELM(input_dim=input_dim, hidden_dim=hidden_dim)
        elm_model.fit(X_train, y_train)

        # Make predictions using the model
        predictions = elm_model.predict(X_test)

        # Convert predictions to binary classes based on threshold
        predictions_binary = (predictions > 0.5).astype(int)

        # Calculate accuracy
        accuracy = accuracy_score(y_test, predictions_binary)
        accuracy_scores.append(accuracy)

    # Print average accuracy for the current target variable
    print(f"Average accuracy for {df.columns[target_index]}: {np.mean(accuracy_scores):.2f}")

# Initialize a dictionary to hold accuracy scores for each target variable
accuracy_dict = {}


# Perform stratified K-Fold cross-validation for each target variable
for target_index in range(y_binary.shape[1]):
    print(f"Evaluating target variable: {df.columns[target_index]}")
    accuracy_scores = []

    for fold, (train_index, test_index) in enumerate(skf.split(X, y_binary[:, target_index])):  # Stratify by the current target
        X_train, X_test = X[train_index], X[test_index]
        y_train, y_test = y_binary[train_index, target_index], y_binary[test_index, target_index]

        # Initialize and train the ELM model
        input_dim = X_train.shape[1]
        hidden_dim = 70
        elm_model = ELM(input_dim=input_dim, hidden_dim=hidden_dim)
        elm_model.fit(X_train, y_train)

        # Make predictions using the model
        predictions = elm_model.predict(X_test)

        # Convert predictions to binary classes based on threshold
        predictions_binary = (predictions > 0.5).astype(int)

        # Calculate accuracy
        accuracy = accuracy_score(y_test, predictions_binary)
        accuracy_scores.append(accuracy)

    # Store the average accuracy for the current target variable
    accuracy_dict[df.columns[target_index]] = np.mean(accuracy_scores)

# Plot the accuracy as a bar graph
plt.figure(figsize=(12, 6))
plt.bar(accuracy_dict.keys(), accuracy_dict.values(), color='skyblue')
plt.xlabel('Target Variables')
plt.ylabel('Accuracy')
plt.title('Accuracy of Predicted Target Values')
plt.xticks(rotation=45)
plt.ylim(0, 1)  # Set y-axis limits from 0 to 1
plt.grid(axis='y')
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import mean_squared_error

# Load the data
df = pd.read_csv('retaildata.csv')

# Convert 'Date' column to datetime format and extract features
df['Date'] = pd.to_datetime(df['Date'], format="%d/%m/%Y")
df['Year'] = df['Date'].dt.year
df['Month'] = df['Date'].dt.month
df['Day'] = df['Date'].dt.day
df.drop('Date', axis=1, inplace=True)

# Define features (X) and target (y)
X = df[['Year', 'Month', 'Day']].values
y = df[['Rice', 'Wheat', 'Atta (Wheat)', 'Gram Dal', 'Tur/Arhar Dal',
         'Urad Dal', 'Moong Dal', 'Masoor Dal', 'Sugar', 'Milk @',
         'Groundnut Oil (Packed)', 'Mustard Oil (Packed)', 'Vanaspati (Packed)',
         'Soya Oil (Packed)', 'Sunflower Oil (Packed)', 'Palm Oil (Packed)',
         'Gur', 'Tea Loose', 'Salt Pack (Iodised)', 'Potato', 'Onion', 'Tomato']].values

# Convert target variables to binary classes based on a threshold
threshold = 25  # Example threshold; adjust based on your needs
y_binary = (y > threshold).astype(int)

# Scale features
scaler = StandardScaler()
X = scaler.fit_transform(X)

# Initialize Stratified K-Fold
skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)

# Define the ELM model
class ELM:
    def __init__(self, input_dim, hidden_dim, regularization=0.0):
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        self.regularization = regularization
        self.W = None
        self.b = None
        self.beta = None

    def fit(self, X, y):
        self.W = np.random.randn(self.hidden_dim, self.input_dim)
        self.b = np.random.randn(self.hidden_dim, 1)

        H = self._hidden_layer_output(X)
        I = np.eye(H.shape[1])
        self.beta = np.linalg.pinv(H.T @ H + self.regularization * I) @ H.T @ y

    def _hidden_layer_output(self, X):
        return 1 / (1 + np.exp(- (X @ self.W.T + self.b.T)))

    def predict(self, X):
        H = self._hidden_layer_output(X)
        return H @ self.beta

# Perform stratified K-Fold cross-validation for each target variable
total_mse = 0

for target_index in range(y_binary.shape[1]):
    print(f"Evaluating target variable: {df.columns[target_index]}")
    mse_scores = []

    for fold, (train_index, test_index) in enumerate(skf.split(X, y_binary[:, target_index])):  # Stratify by the current target
        print(f"Starting fold {fold + 1}...")

        X_train, X_test = X[train_index], X[test_index]
        y_train, y_test = y_binary[train_index, target_index], y_binary[test_index, target_index]

        # Initialize and train the ELM model
        input_dim = X_train.shape[1]
        hidden_dim = 70
        elm_model = ELM(input_dim=input_dim, hidden_dim=hidden_dim)
        elm_model.fit(X_train, y_train)

        # Make predictions using the model
        predictions = elm_model.predict(X_test)

        # Convert predictions to binary classes based on threshold
        predictions_binary = (predictions > 0.5).astype(int)

        # Calculate MSE
        mse = mean_squared_error(y_test, predictions_binary)
        mse_scores.append(mse)

    # Calculate the average MSE for the current target variable
    avg_mse = np.mean(mse_scores)
    print(f"Average MSE for {df.columns[target_index]}: {avg_mse:.2f}")

    # Accumulate the total MSE
    total_mse += avg_mse

# Print the total MSE
print(f"Total MSE across all target variables: {total_mse:.2f}")

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import mean_squared_error

# Load the data
df = pd.read_csv('retaildata.csv')

# Convert 'Date' column to datetime format and extract features
df['Date'] = pd.to_datetime(df['Date'], format="%d/%m/%Y")
df['Year'] = df['Date'].dt.year
df['Month'] = df['Date'].dt.month
df['Day'] = df['Date'].dt.day
df.drop('Date', axis=1, inplace=True)

# Define features (X) and target (y)
X = df[['Year', 'Month', 'Day']].values
y = df[['Rice', 'Wheat', 'Atta (Wheat)', 'Gram Dal', 'Tur/Arhar Dal',
         'Urad Dal', 'Moong Dal', 'Masoor Dal', 'Sugar', 'Milk @',
         'Groundnut Oil (Packed)', 'Mustard Oil (Packed)', 'Vanaspati (Packed)',
         'Soya Oil (Packed)', 'Sunflower Oil (Packed)', 'Palm Oil (Packed)',
         'Gur', 'Tea Loose', 'Salt Pack (Iodised)', 'Potato', 'Onion', 'Tomato']].values

# Convert target variables to binary classes based on a threshold
threshold = 25  # Example threshold; adjust based on your needs
y_binary = (y > threshold).astype(int)

# Scale features
scaler = StandardScaler()
X = scaler.fit_transform(X)

# Initialize Stratified K-Fold
skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)

# Define the ELM model
class ELM:
    def __init__(self, input_dim, hidden_dim, regularization=0.0):
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        self.regularization = regularization
        self.W = None
        self.b = None
        self.beta = None

    def fit(self, X, y):
        self.W = np.random.randn(self.hidden_dim, self.input_dim)
        self.b = np.random.randn(self.hidden_dim, 1)

        H = self._hidden_layer_output(X)
        I = np.eye(H.shape[1])
        self.beta = np.linalg.pinv(H.T @ H + self.regularization * I) @ H.T @ y

    def _hidden_layer_output(self, X):
        return 1 / (1 + np.exp(- (X @ self.W.T + self.b.T)))

    def predict(self, X):
        H = self._hidden_layer_output(X)
        return H @ self.beta

# Initialize total MSE
total_mse = 0
num_targets = y_binary.shape[1]

# Perform stratified K-Fold cross-validation for each target variable
for target_index in range(num_targets):
    print(f"Evaluating target variable: {df.columns[target_index]}")
    mse_scores = []

    for fold, (train_index, test_index) in enumerate(skf.split(X, y_binary[:, target_index])):  # Stratify by the current target
        print(f"Starting fold {fold + 1}...")

        X_train, X_test = X[train_index], X[test_index]
        y_train, y_test = y_binary[train_index, target_index], y_binary[test_index, target_index]

        # Initialize and train the ELM model
        input_dim = X_train.shape[1]
        hidden_dim = 70
        elm_model = ELM(input_dim=input_dim, hidden_dim=hidden_dim)
        elm_model.fit(X_train, y_train)

        # Make predictions using the model
        predictions = elm_model.predict(X_test)

        # Convert predictions to binary classes based on threshold
        predictions_binary = (predictions > 0.5).astype(int)

        # Calculate MSE
        mse = mean_squared_error(y_test, predictions_binary)
        mse_scores.append(mse)

    # Calculate the average MSE for the current target variable
    avg_mse = np.mean(mse_scores)
    print(f"Average MSE for {df.columns[target_index]}: {avg_mse:.2f}")

    # Accumulate the total MSE
    total_mse += avg_mse

# Print the total MSE
print(f"Total MSE across all target variables: {total_mse:.2f}")
